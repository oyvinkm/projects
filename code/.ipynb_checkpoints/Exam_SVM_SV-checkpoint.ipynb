{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2)\n",
      "(800,)\n",
      "(200, 2)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn import svm, model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# this one is only needed if you want to use dictionary in getOptimalSVM\n",
    "import operator\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "data = np.loadtxt('data/dataSVM.txt')\n",
    "\n",
    "features = data[0:int(len(data) * 0.8), :-1]\n",
    "labels = data[0:int(len(data) * 0.8), 2]\n",
    "testingFeatures = data[int(len(data) * 0.8):, :-1]\n",
    "testingLabels = data[int(len(data) * 0.8):, 2]\n",
    "\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(testingFeatures.shape)\n",
    "print(testingLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, Y, cmap = 'Paired_r'):\n",
    "    \"\"\"\n",
    "    This function visualizes the input data X, colored according to labels Y, \n",
    "    superimposed over the decision boundary of the classifier clf\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:,0].min() - 10*h, X[:,0].max() + 10*h\n",
    "    y_min, y_max = X[:,1].min() - 10*h, X[:,1].max() + 10*h\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.contourf(xx, yy, Z, cmap = cmap, alpha = 0.25)\n",
    "    plt.contour(xx, yy, Z, colors = 'k', linewidths = 0.7)\n",
    "    plt.scatter(X[:,0], X[:,1], c = Y, cmap = cmap, edgecolors = 'k');\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-72-cfd064bad8d5>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-72-cfd064bad8d5>\"\u001b[0;36m, line \u001b[0;32m72\u001b[0m\n\u001b[0;31m    SVM = svm.SVC(kernel = 'linear', C)\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#NOTE: it is only allowed to use imports specified at the top of the document, you should not write any addional import\n",
    "\n",
    "class CrossValidation_SVM:\n",
    "    \n",
    "    def __init__(self, n_folds = 5, parameterCList = [0.001, 0.01, 0.1, 1, 10, 100]):\n",
    "        \"\"\"\n",
    "        Initializes the cross-validation class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_folds : the number of folds we expect to use for cross-validation\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n_folds = n_folds\n",
    "        self.parameterCList = parameterCList\n",
    "    \n",
    "    def __generateNextSplit(self, features, labels, train, test):\n",
    "        \"\"\"\n",
    "        Use this function to generate the next split of the input features and labels into \n",
    "        training and validation parts\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features : Array of shape NxM\n",
    "        labels   : Array of length N\n",
    "        kfold    : iterator\n",
    "        \n",
    "        N is the number of samples, M is the number of features\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        trainingFeatures   : subportion of the features selected for training using the current split\n",
    "        trainingLabels     : subportion of the labels selected for training using the current split\n",
    "        validationFeatures : subportion of the features selected for validation using the current split\n",
    "        validationLabels   : subportion of the labels selected for validation using the current split\n",
    "        \"\"\"\n",
    "        trainingFeatures   = None\n",
    "        trainingLabels     = None\n",
    "        validationFeatures = None\n",
    "        validationLabels = None    \n",
    "        trainingFeatures, trainingLabels, validationFeatures, validationLabels = \\\n",
    "        features[train], labels[train], features[test], labels[test]    \n",
    "        trainingFeatures, trainingLabels, validationFeatures, validationLabels =\\\n",
    "        np.array(trainingFeatures), np.array(trainingLabels), np.array(validationFeatures),\\\n",
    "        np.array(validationLabels)\n",
    "        return trainingFeatures, trainingLabels, validationFeatures, validationLabels\n",
    "    \n",
    "    def computeErrorForSpecificC(self, features, labels, C):\n",
    "        \"\"\"\n",
    "        Iterate throught all splits and compute the SVM performance using the specified C.\n",
    "        Use a linear kernel for the SVM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : Array of shape NxM\n",
    "        labels   : Array of length N\n",
    "        C : svm regularization parameter\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        meanAccuracy : mean validation accuracy computer over all splits\n",
    "        \"\"\"         \n",
    "        C = self.parameterCList\n",
    "        accuracyArray = []\n",
    "        \n",
    "        # this function should use __generateNextSplit for iterating over splits\n",
    "        # The iterator over folds. If you don't want to use it, feel free to implement your own iterator\n",
    "        kfold = KFold(self.n_folds, shuffle = False)\n",
    "        for train, test in kfold.split(features):\n",
    "            x_train, t_train, x_test, t_test = \\\n",
    "            self.__generateNextSplit(features, labels, train, test)\n",
    "            SVM = svm.SVC(kernel = 'linear', C)\n",
    "            accuracyArray.append(SVM.score(x_test, t_test))\n",
    "        return np.mean(accuracyArray)\n",
    "    \n",
    "    #def getOptimalSVM(self, features, labels):\n",
    "        \"\"\"\n",
    "        Iterate through all C from self.parameterCList to find the optimal one, and generate the corresponding SVM classifier\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features : Array of shape NxM\n",
    "        labels   : Array of length N\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        clf : the optimal SVM classfier trained on all input features and labels using optimal C\n",
    "        accuracyList : the list of mean accuracies for each C from self.parameterCList.\n",
    "                       accuracyList should be of the length len(self.parameterCList) \n",
    "        \"\"\"\n",
    "        \n",
    "        accuracyList = []# if you want and know how, you can use dictionary here: accuracyDict = {}\n",
    "        # TODO: ADD YOUR CODE HERE\n",
    "        #   1) go through all C in self.parameterCList using __computeErrorForSpecificC\n",
    "        #   2) memorize mean accuracies for different C into accuracyList\n",
    "        #   3) find the optimal C with the highest mean accuracy\n",
    "        #   4) train clf on all input features and label using the optimal C\n",
    "        \n",
    "        \n",
    "        return clf, accuracyList\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 2)\n",
      "(640,)\n",
      "(160, 2)\n",
      "(160,)\n",
      "(640, 2)\n",
      "(640,)\n",
      "(160, 2)\n",
      "(160,)\n",
      "(640, 2)\n",
      "(640,)\n",
      "(160, 2)\n",
      "(160,)\n",
      "(640, 2)\n",
      "(640,)\n",
      "(160, 2)\n",
      "(160,)\n",
      "(640, 2)\n",
      "(640,)\n",
      "(160, 2)\n",
      "(160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the code to test your cross-validation implementation.\n",
    "tester = CrossValidation_SVM(n_folds = 5, parameterCList = [0.001, 0.01, 0.1, 1, 10, 100])\n",
    "tester.computeErrorForSpecificC(features, labels, C)\n",
    "#clf, accuracyList = tester.getOptimalSVM(features, labels)\n",
    "#print(accuracyList)\n",
    "#plot_decision_boundary(clf, testingFeatures, testingLabels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
